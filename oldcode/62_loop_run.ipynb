{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation loop\n",
    "\n",
    "Run for 2 month period, loop over files pulling 7(?) days material, interpolate and calculate adjustemnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import datetime\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393500 453500 4472000 4532000\n"
     ]
    }
   ],
   "source": [
    "## -----------------------\n",
    "## Prep grid (mostly for bounds)\n",
    "grid_gdf = gpd.read_file(\"./data/coarse_grid_pts/grid_pts_coarse.shp\")\n",
    "grid_gdf = grid_gdf.set_crs(4326, allow_override=True)\n",
    "grid_gdf = grid_gdf.to_crs(32612)\n",
    "\n",
    "## Grid min/max (replaced by set limits below)\n",
    "grid_crds = grid_gdf.get_coordinates()\n",
    "min_x = grid_crds.x.min()\n",
    "max_x = grid_crds.x.max()\n",
    "min_y = grid_crds.y.min()\n",
    "max_y = grid_crds.y.max()\n",
    "\n",
    "## Updated to help estimate of basis functions\n",
    "min_x = 393500\n",
    "max_x = 453500\n",
    "min_y = 4472000\n",
    "max_y = 4532000\n",
    "print(min_x, max_x, min_y, max_y)\n",
    "\n",
    "## Standardize coordinates\n",
    "grid_crds['normalized_east'] = (grid_crds['x']-min_x)/(max_x - min_x)\n",
    "grid_crds['normalized_north'] = (grid_crds['y']-min_y)/(max_y-min_y)\n",
    "\n",
    "## -----------------------\n",
    "## Air monitor data\n",
    "aq_df = pd.read_csv(\"./data/loop_test/summer23_ozone_stationary.csv\")\n",
    "aq_df['day_time'] = pd.to_datetime(aq_df['day_time']).dt.tz_localize(None)\n",
    "## add the timezone:\n",
    "aq_df['day_time'] = aq_df['day_time'] + pd.Timedelta(hours=7)\n",
    "\n",
    "## Convert to geopandas\n",
    "aq_gdf = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy(aq_df.longitude, aq_df.latitude, crs=\"EPSG:4326\"), data=aq_df\n",
    ")\n",
    "aq_gdf = aq_gdf.to_crs(32612)\n",
    "\n",
    "## Standardize coordinates\n",
    "aq_crds = aq_gdf.get_coordinates()\n",
    "lon = aq_crds.x\n",
    "lat = aq_crds.y\n",
    "aq_df['normalized_east'] = (lon-min_x)/(max_x - min_x)\n",
    "aq_df['normalized_north'] = (lat-min_y)/(max_y-min_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-01 00:00:00</td>\n",
       "      <td>40.70350</td>\n",
       "      <td>-111.97723</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-01 00:00:00</td>\n",
       "      <td>40.69294</td>\n",
       "      <td>-111.96915</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-01 00:00:00</td>\n",
       "      <td>40.69298</td>\n",
       "      <td>-111.96718</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-01 00:01:00</td>\n",
       "      <td>40.70347</td>\n",
       "      <td>-111.97723</td>\n",
       "      <td>0.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-01 00:01:00</td>\n",
       "      <td>40.69294</td>\n",
       "      <td>-111.97194</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177066</th>\n",
       "      <td>2023-06-30 23:58:00</td>\n",
       "      <td>40.69344</td>\n",
       "      <td>-111.96056</td>\n",
       "      <td>0.0560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177067</th>\n",
       "      <td>2023-06-30 23:59:00</td>\n",
       "      <td>40.69312</td>\n",
       "      <td>-111.96054</td>\n",
       "      <td>0.0546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177068</th>\n",
       "      <td>2023-06-30 23:59:00</td>\n",
       "      <td>40.70405</td>\n",
       "      <td>-111.97715</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177069</th>\n",
       "      <td>2023-06-30 23:59:00</td>\n",
       "      <td>40.76354</td>\n",
       "      <td>-111.90943</td>\n",
       "      <td>0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177070</th>\n",
       "      <td>2023-06-30 23:59:00</td>\n",
       "      <td>40.69295</td>\n",
       "      <td>-111.96404</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177071 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time       lon        lat     val\n",
       "0      2023-07-01 00:00:00  40.70350 -111.97723  0.0573\n",
       "1      2023-07-01 00:00:00  40.69294 -111.96915  0.0604\n",
       "2      2023-07-01 00:00:00  40.69298 -111.96718  0.0578\n",
       "3      2023-07-01 00:01:00  40.70347 -111.97723  0.0525\n",
       "4      2023-07-01 00:01:00  40.69294 -111.97194  0.0610\n",
       "...                    ...       ...        ...     ...\n",
       "177066 2023-06-30 23:58:00  40.69344 -111.96056  0.0560\n",
       "177067 2023-06-30 23:59:00  40.69312 -111.96054  0.0546\n",
       "177068 2023-06-30 23:59:00  40.70405 -111.97715  0.0578\n",
       "177069 2023-06-30 23:59:00  40.76354 -111.90943  0.0589\n",
       "177070 2023-06-30 23:59:00  40.69295 -111.96404  0.0585\n",
       "\n",
       "[177071 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## -----------------------\n",
    "## EBus data\n",
    "ebus = pd.read_csv(\"./data/loop_test/ebus_2023_06-07.csv\", header = [0,1],  \n",
    "                 na_values = -9999.00)\n",
    "ebus2_df = pd.DataFrame({\n",
    "    'time': pd.to_datetime(ebus.iloc[:,1]),\n",
    "    'lon': ebus.iloc[:,2],\n",
    "    'lat': ebus.iloc[:,3]\n",
    "    })\n",
    "ebus2_df['val'] = ebus['O3'] / 1000\n",
    "\n",
    "ebus2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to geopandas\n",
    "ebus2_gdf = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy(ebus2_df.lon, ebus2_df.lat, crs=\"EPSG:4326\"), data=ebus2_df\n",
    ")\n",
    "ebus2_gdf = ebus2_gdf.to_crs(32612)\n",
    "\n",
    "## Standardize coordinates\n",
    "ebus2_crds = ebus2_gdf.get_coordinates()\n",
    "lon = ebus2_crds.x\n",
    "lat = ebus2_crds.y\n",
    "ebus2_df['normalized_east'] = (lon-min_x)/(max_x - min_x)\n",
    "ebus2_df['normalized_north'] = (lat-min_y)/(max_y-min_y)\n",
    "\n",
    "## plt.plot(grid_crds['normalized_east'], grid_crds['normalized_north'], 'bo', markersize=1)\n",
    "## plt.plot(ebus2_df['normalized_east'], ebus2_df['normalized_north'], 'ro', markersize=2)\n",
    "## plt.plot(aq_df['normalized_east'], aq_df['normalized_north'], 'go')\n",
    "## plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------\n",
    "## Basis functions\n",
    "\n",
    "## Function to make knots in 1D space/time [0, 1]. Pass vector of number of knots in 1D\n",
    "def make_knots_time(n):\n",
    "    knots = [np.linspace(0,1,int(i)) for i in n]\n",
    "    return(knots)\n",
    "\n",
    "## Function to make Gaussian BFs along one dimension\n",
    "def get_basis_gaussian_1d(s, num_basis, knots, std_arr):\n",
    "    N = len(s)\n",
    "    phi = np.zeros((N, sum(num_basis)))\n",
    "    K = 0\n",
    "    for res in range(len(num_basis)):\n",
    "        std = std_arr[res]\n",
    "        for i in range(num_basis[res]):\n",
    "            d = np.square(np.absolute(s-knots[res][i]))\n",
    "            for j in range(len(d)):\n",
    "                if d[j] >= 0 and d[j] <= 1:\n",
    "                    phi[j,i + K] = np.exp(-0.5 * d[j]/(std**2))\n",
    "                else:\n",
    "                    phi[j,i + K] = 0\n",
    "        K = K + num_basis[res]\n",
    "    return(phi)\n",
    "\n",
    "## Function to make knots in 2D space [0, 1]. Pass vector of number of knots in 2D (i.e. res of 5, pass 25)\n",
    "def make_knots_space(n):\n",
    "    knots = [np.linspace(0,1,int(np.sqrt(i))) for i in n]\n",
    "    return knots\n",
    "\n",
    "## Function to make Wendland BFs over two dimensions\n",
    "def get_basis_wendland_2d(s, num_basis, knots_1d):\n",
    "    ## Get weights from Wendland kernel\n",
    "    N = len(s)\n",
    "    K = 0\n",
    "    phi = np.zeros((N, sum(num_basis)))\n",
    "    for res in range(len(num_basis)):\n",
    "        theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "        knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "        knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "        for i in range(num_basis[res]):\n",
    "            d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "            for j in range(len(d)):\n",
    "                if d[j] >= 0 and d[j] <= 1:\n",
    "                    phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "                else:\n",
    "                    phi[j,i + K] = 0\n",
    "        K = K + num_basis[res]\n",
    "    return(phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -----------------------\n",
    "## Main loop\n",
    "\n",
    "all_days = aq_df.date.unique()\n",
    "all_days = all_days[6:]\n",
    "for i in all_days:\n",
    "    print(\"## -------------- ##\")\n",
    "    print(f\"Running for {i}\")\n",
    "    target_date = pd.to_datetime(i)\n",
    "    print(target_date)\n",
    "    start_date = target_date - pd.to_timedelta(7, unit='d')\n",
    "    print(start_date)\n",
    "\n",
    "    ## ------------------------------------------------------------------------\n",
    "    ## Extract monitor data\n",
    "    print(\"Prepping monitor data\")\n",
    "    print(aq_df['day_time'].dtype)\n",
    "    aq_df_sub = aq_df[(aq_df['day_time'] >= start_date) & (aq_df['day_time'] <= target_date)]\n",
    "    print(aq_df_sub.shape)\n",
    "    day_time = aq_df_sub['day_time'].astype('int64') / 1e9 ## Time in nanoseconds\n",
    "    min_t = day_time.min()\n",
    "    max_t = day_time.max()\n",
    "    aq_df_sub['normalized_time'] = (day_time - min_t) / (max_t-min_t)\n",
    "\n",
    "    ## Create knots for time basis - 14 day basis function (/2 for 7 day)\n",
    "    num_basis_t = [10,20,56]\n",
    "    std_arr_t = [0.3,0.15,0.05]\n",
    "    knots_1d_t = make_knots_time(num_basis_t)\n",
    "\n",
    "    ## Create time basis for monitor data\n",
    "    s = np.array(aq_df_sub['normalized_time']).reshape(len(aq_df_sub),1)\n",
    "    phi_t1 = get_basis_gaussian_1d(s, num_basis_t, knots_1d_t, std_arr_t)\n",
    "    print(phi_t1.shape)\n",
    "\n",
    "    ## Knots for spatial dimension (from STDK example)\n",
    "    num_basis_s = [7**2,13**2,25**2] ## For 60km grid this is 10/5/2.5 resolution\n",
    "    knots_1d_s = make_knots_space(num_basis_s)\n",
    "    \n",
    "    ## Create time basis for monitor data\n",
    "    s = np.vstack((aq_df_sub['normalized_east'],aq_df_sub['normalized_north'])).T\n",
    "    phi_s1 = get_basis_wendland_2d(s, num_basis_s, knots_1d_s)\n",
    "    print(phi_s1.shape)\n",
    "\n",
    "    phi_1 = np.hstack((phi_t1,phi_s1))\n",
    "    idx_zero = np.array([], dtype=int)\n",
    "    for i in range(phi_1.shape[1]):\n",
    "        if sum(phi_1[:,i]!=0)==0:\n",
    "            idx_zero = np.append(idx_zero,int(i))\n",
    "    \n",
    "    phi_1_reduce = np.delete(phi_1,idx_zero,1)\n",
    "    print(phi_1.shape)\n",
    "    print(phi_1_reduce.shape)\n",
    "\n",
    "    ## ------------------------------------------------------------------------\n",
    "    ## EBus data\n",
    "    print(\"Prepping EBus data\")\n",
    "    start_date_pred = target_date - pd.to_timedelta(1, unit='d')\n",
    "    print(ebus2_df['time'].dtype)\n",
    "    print(\"target_date\")\n",
    "    print(target_date)\n",
    "    print(target_date.__class__)\n",
    "    print(\"start_date_pred\")\n",
    "    print(start_date_pred)\n",
    "    print(start_date_pred.__class__)\n",
    "    ebus2_df_sub = ebus2_df[(ebus2_df['time'] > start_date_pred) & (ebus2_df['time'] <= target_date)]\n",
    "    print(ebus2_df_sub.shape)\n",
    "    print(\"## ------------- ##\")\n",
    "    print(ebus2_df['time'] > start_date_pred)\n",
    "    print(\"## ------------- ##\")\n",
    "    print(ebus2_df['time'] <= target_date)\n",
    "    print(\"## ------------- ##\")\n",
    "\n",
    "    day_time = ebus2_df_sub['time'].astype('int64') / 1e9 ## Time in nanoseconds\n",
    "    print(\"time\")\n",
    "    print(ebus2_df['time'])\n",
    "    print(\"day_time\")\n",
    "    print(day_time)\n",
    "    ebus2_df_sub['normalized_time'] = (day_time - min_t) / (max_t-min_t)\n",
    "\n",
    "    s = np.array(ebus2_df_sub['normalized_time']).reshape(len(ebus2_df_sub),1)\n",
    "    phi_t2 = get_basis_gaussian_1d(s, num_basis_t, knots_1d_t, std_arr_t)\n",
    "    print(phi_t2.shape)\n",
    "\n",
    "    s = np.vstack((ebus2_df_sub['normalized_east'],ebus2_df_sub['normalized_north'])).T\n",
    "    phi_s2 = get_basis_wendland_2d(s, num_basis_s, knots_1d_s)\n",
    "    print(phi_s2.shape)\n",
    "\n",
    "    phi_2 = np.hstack((phi_t2,phi_s2))\n",
    "    phi_2_reduce = np.delete(phi_2,idx_zero,1)\n",
    "    print(phi_2.shape)\n",
    "    print(phi_2_reduce.shape)\n",
    "    \n",
    "    ## ------------------------------------------------------------------------\n",
    "    ## Random forest\n",
    "    print(\"Running RF model\")\n",
    "    ## Create arrays for training RF\n",
    "    X_train = phi_1_reduce\n",
    "    y_train = aq_df_sub['sample.measurement'].values\n",
    "\n",
    "    ## Create and train\n",
    "    #aq_rf = ensemble.RandomForestRegressor()\n",
    "    #aq_rf.fit(X_train, y_train)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = \"2023-06-09\"\n",
    "print(\"## -------------- ##\")\n",
    "print(f\"Running for {i}\")\n",
    "target_date = pd.to_datetime(i)\n",
    "print(target_date)\n",
    "start_date = target_date - pd.to_timedelta(7, unit='d')\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------------------------------------------------------\n",
    "## Extract monitor data\n",
    "print(\"Prepping monitor data\")\n",
    "print(aq_df['day_time'].dtype)\n",
    "aq_df_sub = aq_df[(aq_df['day_time'] >= start_date) & (aq_df['day_time'] <= target_date)]\n",
    "print(aq_df_sub.shape)\n",
    "day_time = aq_df_sub['day_time'].astype('int64') / 1e9 ## Time in nanoseconds\n",
    "min_t = day_time.min()\n",
    "max_t = day_time.max()\n",
    "aq_df_sub['normalized_time'] = (day_time - min_t) / (max_t-min_t)\n",
    "\n",
    "## Create knots for time basis - 14 day basis function (/2 for 7 day)\n",
    "num_basis_t = [10,20,56]\n",
    "std_arr_t = [0.3,0.15,0.05]\n",
    "knots_1d_t = make_knots_time(num_basis_t)\n",
    "\n",
    "## Create time basis for monitor data\n",
    "s = np.array(aq_df_sub['normalized_time']).reshape(len(aq_df_sub),1)\n",
    "phi_t1 = get_basis_gaussian_1d(s, num_basis_t, knots_1d_t, std_arr_t)\n",
    "print(phi_t1.shape)\n",
    "\n",
    "## Knots for spatial dimension (from STDK example)\n",
    "num_basis_s = [7**2,13**2,25**2] ## For 60km grid this is 10/5/2.5 resolution\n",
    "knots_1d_s = make_knots_space(num_basis_s)\n",
    "\n",
    "## Create time basis for monitor data\n",
    "s = np.vstack((aq_df_sub['normalized_east'],aq_df_sub['normalized_north'])).T\n",
    "phi_s1 = get_basis_wendland_2d(s, num_basis_s, knots_1d_s)\n",
    "print(phi_s1.shape)\n",
    "\n",
    "phi_1 = np.hstack((phi_t1,phi_s1))\n",
    "idx_zero = np.array([], dtype=int)\n",
    "for i in range(phi_1.shape[1]):\n",
    "    if sum(phi_1[:,i]!=0)==0:\n",
    "        idx_zero = np.append(idx_zero,int(i))\n",
    "\n",
    "phi_1_reduce = np.delete(phi_1,idx_zero,1)\n",
    "print(phi_1.shape)\n",
    "print(phi_1_reduce.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------------------------------------------------------------\n",
    "## EBus data\n",
    "print(\"Prepping EBus data\")\n",
    "start_date_pred = target_date - pd.to_timedelta(1, unit='d')\n",
    "print(ebus2_df['time'].dtype)\n",
    "print(\"target_date\")\n",
    "print(target_date)\n",
    "print(target_date.__class__)\n",
    "print(\"start_date_pred\")\n",
    "print(start_date_pred)\n",
    "print(start_date_pred.__class__)\n",
    "ebus2_df_sub = ebus2_df[(ebus2_df['time'] > start_date_pred) & (ebus2_df['time'] <= target_date)]\n",
    "print(ebus2_df_sub.shape)\n",
    "print(\"## ------------- ##\")\n",
    "print(ebus2_df['time'] > start_date_pred)\n",
    "print(\"## ------------- ##\")\n",
    "print(ebus2_df['time'] <= target_date)\n",
    "print(\"## ------------- ##\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebus2_df['time'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebus2_df['time'][0])\n",
    "print(start_date_pred)\n",
    "ebus2_df['time'][0] > start_date_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebus2_df['time'][0])\n",
    "td2 = pd.to_datetime(\"2023-07-08\")\n",
    "print(td2)\n",
    "ebus2_df['time'][0] < td2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ebus2_df['time'] > start_date_pred\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ebus2_df['time'] <= target_date\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebus2_df['time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_time = ebus2_df_sub['time'].astype('int64') / 1e9 ## Time in nanoseconds\n",
    "print(\"time\")\n",
    "print(ebus2_df['time'])\n",
    "print(\"day_time\")\n",
    "print(day_time)\n",
    "ebus2_df_sub['normalized_time'] = (day_time - min_t) / (max_t-min_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array(ebus2_df_sub['normalized_time']).reshape(len(ebus2_df_sub),1)\n",
    "phi_t2 = get_basis_gaussian_1d(s, num_basis_t, knots_1d_t, std_arr_t)\n",
    "print(phi_t2.shape)\n",
    "\n",
    "s = np.vstack((ebus2_df_sub['normalized_east'],ebus2_df_sub['normalized_north'])).T\n",
    "phi_s2 = get_basis_wendland_2d(s, num_basis_s, knots_1d_s)\n",
    "print(phi_s2.shape)\n",
    "\n",
    "phi_2 = np.hstack((phi_t2,phi_s2))\n",
    "phi_2_reduce = np.delete(phi_2,idx_zero,1)\n",
    "print(phi_2.shape)\n",
    "print(phi_2_reduce.shape)\n",
    "\n",
    "## ------------------------------------------------------------------------\n",
    "## Random forest\n",
    "print(\"Running RF model\")\n",
    "## Create arrays for training RF\n",
    "X_train = phi_1_reduce\n",
    "y_train = aq_df_sub['sample.measurement'].values\n",
    "\n",
    "## Create and train\n",
    "#aq_rf = ensemble.RandomForestRegressor()\n",
    "#aq_rf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
